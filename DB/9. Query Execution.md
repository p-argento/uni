## DBMS Architecture

![[Pasted image 20240521093251.png]]

Most DBMS share the same architecture.
It is divided in
1. relational engine
2. storage engine

The storage engine is composed by
	1. access method manager (like open/scan a file/index)
	2. storage structures manager (like hash tables, indexes)
	3. buffer manager (similar to the OS)
	4. concurrency manager (solve concurrency problems)
	5. transaction manager (assure atomicity and durability of transactions)

On top of this storage engine, SQL is built.
It is executed in the relational engine, composed by
1. query manager
	1. query optimizer, a tool that transform a query into an optimize query (the kernel of sql)
	2. access plan manager, execute it using access methods

We will study in order
1. permanent memory manager, buffer manager and storage structures
2. query optimizer and access plan manager
3. transaction management and concurrency manager

# 1. persistent memory manager, buffer manager and storage structures
## Persistent Memory Manager

We start from memory, we distinguish
1. persistent memory (slow, big, robust)
2. main memory (fast, small, volatile)
Whenever there is a system crash, the content of the main memory is lost.
If you want to read, analyze any data, it must be done in the main memory.
Data must be first loaded from persistent memory to main memory.

Persistent memory comes into 2 shapes.
1. Hard Disk Drives (HDD) with rotating disk.
2. Solid State Drives (SDD) that is more expensive and fast.
Most databases in the world are on disk. But they are incredibly slow.
To do an entire spin, it take 5 ms, basically forever.

Main memory is random access, meaning that you move 1 byte at a time, taking microseconds.
While in HDD, you need to read a page (4kbyte) at a time, taking 10 ms.

Whenever you analyze an algo that runs on persistent storage, you need to measure in pages. How many pages do I have to read in order to do something?

Instead of persistent memory or HDD or SSD, we will just say "disk".

The permanent memory manager is just implementing the basic operations on different OS.

## Buffer Manager

![[Pasted image 20240521101528.png]]

In order to operate on a page of data, you must first load the page from disk into main memory. But they have different orders of magnitude.
The buffer decides which pages to load and when.
The frames are data structures that have PageID and FrameID.
For each frame, the buffer manger contains
1. PinCount
	1. is the number of clients who are currently using that page
	2. when a transaction it is asked, the buffer manager decides to free a frame to load a new page if it was not already there
	3. like a pin to say "do not move this page", meaning that it can be removed only if no one is using it
2. dirty pin
	1. means that somebody as modified this page, so it is different from the one present on disk
	2. when it happens, the buffer must first "flush", updating the disk, then the page is available for eviction (removing from buffer)
3. page

The methods are
1. getAndPinPage
2. unpinPage
3. setDirty
4. flushPage

We study
1. replacement algo
2. flush algo

The most common "replacement algo" is Least Recently Used (LSU) meaning that the buffer manager keeps a timestamp for each page and it will choose to remove the older if needed.

The "flushing policy" is what should the buffer manager do when the dirty bit is one.
1. (lazy policy)i can flush only when i need space 
	1. it minimizes the number of flashes
2. (eager policy) as soon as i see a dirty bit, i flush
	1. i like to keep my buffer clean
3. (checkpoint approach) every 5 minutes (or different), the buffer manager scans all the pages, and, if there's a dirty bit, it flushes that page.
	1. this is the most common

The essential point is that you do not operate directly on disk, but it must be first moved into the buffer.
Note that you are updating a copy of the page that is in the volatile memory, and those changes might be lost. We will see the LOG manager, that is eager.

Accessing the buffer has zero cost.
In the algos, we assume that there are no pages pinned in the buffer, meaning that we need to load all the pages.

How do we represent tables on disk?
We assume that every record is stored in a page, like 100 records in a page.
We assume that every record is uniquely identified by a Record ID, 
RID=(PageID, Position within the page)
Once you know the RID, you know how to find that record. This RID is persistent.

## Storage Structures
Whenever you have a table, you must decide how you will store this table on disk.
Types
1. Heap organization
	1. whenever you add a new record, it is added at the end of the file
	2. it is the only organizer attribute-neutral, meaning that it does not privilege any attribute
	3. best for a lot of insertions
2. sequential organization
	1. sorted by an important attribute (like the surname)
	2. best if never update but do a lot of range searches
3. hash organization
	1. best if main operation is equality searches
4. tree organization
	1. intermediate, quite good every time

A data organization is a rule that tells the storage manager where to place a new record. Each one has its own strength, no optimal solution.
After you have chosen one optimal, then you can add more secondary organizations.

We use a cost model to decide.
We measure time in terms of pages, "Npag(R)" is the unit of measure.
For each organization, we will ask how much does it cost to perform
1. equality and range search
	1. means retrieve all data where name=giorgio or whose age is between smt
3. update, insertion (this is the main focus), delete

### Heap organization.
This is the most common organization used by dbms.
It is the fastest organization for insertion, since new records are just put at the end of the file. It is (almost) the only one where you read 1gb of data for 1gb of files, while for other organizations you need a little bit of empty space, like 1.2 gb.

Heap is the worst for equality search. And since the equality is probably the most common operations, why are they so popular? Because equalities can be speed up using indexes. The most common approach is using the heap and then add indexes. Adding indexes is not ideal as having the best organization, but it is almost as good.
The advantage is to build an index only later and only if a problem arise. If no problem arise, maybe there is not even the need for a better organization or an index.

It is ideal when
1. insertion is the dominant  operation
	1. like in log files, where we just keep track, but almost never search
2. we almost never do equality and range search, but we do massive search
	1. meaning that we read from top to end, like for computing the average of all values, also called table scan
	2. the heap gives the cheapest table scan, when you read all the records

The cost of equality is
1. (average) NPag(R) / 2
2. (worst) Npag(R)
The average is only for a unique key, otherwise it is always worst because we need to scan the whole table R.

The cost of inserting a tuple is just 2Pag(R).
Why 2? Read the file and write it.
We can do even better, pinning a page that is used often in the buffer, and then unpin it for flushing only when the page is full. Then, start a new blank page pinned for the new entries. Now the cost is 1 write for 100 records, so we pay NPag/NRec, supposed that every page contains 100 records.

The second faster organization for insertion is hash, where the cost is 2.2


### Sequential Organization














*30-04 restarted from 50 min*



# 2. query optimizer and access plan manager

The query manager is composed by
1. query optimizer
2. access plan manager

![[Pasted image 20240521113056.png]]







Since we do not expect users to write their queries in a way that suggests the best strategy for ﬁnding the answer, it is responsibility of the *Query Manager* module of the system to ﬁgure out how to ﬁnd the most efﬁcient way to get the data the user wants.

Query Processing
1. syntactically and semantically correctness
2. transformation into a relational algebra query
3. logical transformation to standardize and simplify the query
4. select a strategy and the algorithms to perform the operations

The result of this process is the *physical query plan*: a tree of physical operators that implement algorithms to execute the relational algebra operators.

Each relational algebra operator can be implemented using several algorithms (physical operators).

For example, the join can be implemented using:
1. nested loops
2. page nested loops
3. index nested loops

[[DB-query-execution.pdf]]


![[Pasted image 20240508144835.png]]
![[Pasted image 20240508144846.png]]
![[Pasted image 20240508144900.png]]
![[Pasted image 20240508144915.png]]

