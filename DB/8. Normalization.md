A couple of weeks about normalization.
Then a couple of weeks about internals.

This is mostly about math.
And theorems are important (no proof).

> Just the correct definition

Why study normalization? To avoid redundancy that ruins the quality of the data.

The goal is to create a good decomposition starting from functional dependencies using an algorithm

## Functional Dependencies
We want an algorithm to design a good schema from an horrible schema.
What does it mean for a schema to be good?
How can we see if they are equivalents?
We use *functional dependencies*.
It distinguish valid instances from invalid instances.
It means that it is not possible to have two lines that coincide on x and not on y.


Given a scheme R(T) and X, Y $\subseteq$ T, a functional dependency ( FD ) is a constraint on the instances of R.
X functionally determines Y, written Xâ†’Y, iff: 
- $\forall$r valid instance of R
- $\forall t1, t2 \in r$
- $\text{ if }  t1[X] = t2[X] \implies t1[Y] = t2[Y]$

## Clause Manipulation
$$True\wedge A \wedge B\implies False \vee C \vee D$$
And you can move variables from right to left and viceversa by negating it.

This allows to manipulate sentences in order to obtain functional dependencies.

## Logical Implication
Simple definition
...

It can be computed using the set of 3 inference rules. Called Armstrong 


## Deduction
What is the difference?


## Closures



## Exercises
[[DB_ex_24_04]]