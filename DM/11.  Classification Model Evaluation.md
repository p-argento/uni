[[DM Classification]]

**Model Evaluation**
1. Metrics for Performance Evaluation -> how to evaluate model
	1. Confusion Matrix and Accuracy
	2. Cost-sensitive measures
	3. Cost matrix
2. Methods for Performance Evaluation -> how to obtain reliable estimates
	1. Holdout
	2. Repeated holdout (random subsampling)
	3. Cross Validation
	4. Stratified sampling
	5. Bootstrap (sampling with replacement)
3. Methods for Model Comparison -> compare performance among competing models
	1. ROC Curve
	2. Lift Chart

![[Pasted image 20231117221520.png]]

# METRICS for performance evaluation
It focus on the predictive capability of the model (not the speed or scalability).

**Confusion matrix**
Compare the vector Y of actual class labels with the vector Y' returned by the trained model for the test set.

![[Pasted image 20231117222744.png|400]]

The relevant measures based on the confusion matrix are
1. accuracy (A)
2. precision (p)
3. recall (r)
4. F-measure (F)

**Accuracy**
The most important metrics is the *accuracy* (the opposite is the error).
$$Accuracy=\frac{correct\ instances}{total\ instances}=\frac{TP+TN}{TP+TN+FP+FN}$$
Limitation of accuracy.
Since true and false have the same importance, if the frequency of classes is very diverse, the accuracy might be misleading.
The model might predict always class 0 with a high accuracy, but we are actually looking for are those few records of class 1.

To avoid this limitation, we can give different importance to true and false, computing the *weighted accuracy*
$$Weighted\ Accuracy=\frac{w_1TP+w_4TN}{w_1TP+w_2TN+w_3FP+w_4FN}$$

**Cost-sensitive measures**
For example, in a factory, you need to be sure (TP) that there is a problem before stopping the machines, avoiding FP. So what you want is high precision.
*Precision* is biased towards C(Yes|Yes) & C(Yes|No).
$$Precision(p)=\frac{TP}{TP+FP}$$
In a hospital, you look for high recall for emergency calls. It means that you don't care about TN, they can be as many as you want, but it is crucial to identify the TP to evacuate the hospital when it is a real emergency.
*Recall* is biased towards C(Yes|Yes) & C(No|Yes)
$$Recall(r)=\frac{TP}{TP+FN}$$
Is it better to have a high precision or a high recall? It depends.  
If you don't know, do the F-measure, which is an harmonic mean.
*F-measure* is biased towards all except C(No|No).
$$F-measure(F)=\frac{2TP}{2TP+FN+FP}=\frac{2rp}{r+p}$$

**Cost Matrix**
In addition to the confusion matrix, we can compute the *cost matrix*.
It uses $C(i|j)$ as the cost of misclassifying class j example as class i.

![[Pasted image 20231117232752.png|300]]

It is used in combination with the confusion matrix to compute the total cost of the model, based on the goal we need to achieve in terms of costs for each event.
The cost matrix provides the weights for each frequency in the confusion matrix. The sum is the total cost.

Multiclass evaluation.








# Validation

![[Pasted image 20231117221417.png]]