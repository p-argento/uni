
## From itemsets to sequences
Sequencies are list of items of objects.

Frequent itemsets and association rules focus on transactions and the items that appear there. on the other hand, databases of transactions usually have a temporal information  and sequential patterns exploit it. It means that the main difference between pattern mining and sequential patter mining is TIME.

Terminology.
1. item (or event)
2. transaction (or element)
	1. collection of items (or events) *at time t*
	2. e_i = {i1, i2, ..., ik}
3. sequence
	1. *ordered* list of transactions
	2. s = < e1, e2, e3, ... >
	3. |s| is the cardinality of a sequence
	4. k-sequence is a sequence that contains k items (k is the size)

For example, in a customer database
1. sequence -> purchase history of a given customer
2. transaction -> set of items bought at time t by a customer
3. item -> books, bread, etc

IMPORTANT.
1. the order within a transaction doesn't matter, but the order of transaction is crucial.
2. time of element = position in the sequence

Distinguish
1. frequent pattern
	1. is an event or a combination of events that appears frequently in the data wrt a threshold
	2. time is not considered
2. frequent *sequential* pattern
	1. is a sequence of events that occur frequently
	2. TIME is important, considering the order of events
	3. DO NOT confuse with association rules

Other formal definitions
1. subsequence
	1. is it contained in a bigger sequence?
2. support of a subsequence
	1. fraction of data sequences that contains the subsequence
3. frequent subsequence
	1. if the support $\geq$ minsup

*DO NOT* count more times the subsequence, just count the sequences where it is there.


## Sequential Pattern Mining
Given
1. a database of sequences
2. a user-specificied threshold for minsup
Find
1. all the subsequences with sup $\geq$ minsup

A trivial approach would generate all possible k-subsequences but that will generate a combinatorial explosion.


# GSP
Meaning Generalized Sequential Pattern

## GSP Idea
The same idea of Apriori, we want to avoid generating useless sequences.
The Apriori principle, in fact, still holds, the difference is that "contains" has a different meaning.

If the support of s1 is below the minsup, then all  the super-sequences containing s1 will have a supp lower than the threshold, so it is useless to generate those sequences.

It means starting from short patterns and find longer ones at each iteration.
(apriori principle) If one sequence s1 is contained in s2, then the support of s2 cannot be larger than that of s1 $$S_1\subseteq S_2 \implies sup(S_1)\geq sup(S_2)$$ The intuition is that any input sequence that contains s2 will also contain s1.

The first step is the same as Apriori, meaning that we remove the subsequences with supp > minsupp.

## GSP Algorithm
Step 1.
1. make the first pass over the sequence database D to yield all the 1-transaction frequent subsequences
Step 2. (repeat until no new subsequences are found)
1. candidate generation
	1. merge pairs of frequent subsequences found in the (k-1)th pass to generate candidate sequences that contain k items
2. candidate pruning (CRUCIAL)
	1. prune candidate k-sequences that contain infrequent (k-1)-subsequences
3. support counting
	1. make a new pass over the sequence database D to find the support for these candidate sequences
4. candidate elimination
	1. eliminate candidate k-sequences where supp < minsup

*REMEMBER*
1. DO NOT forget to prune
	1. only for the remaining subsequences I do the support counting
2. AB is different than BA, because the order matters, and this results in more subsequences
	1. in contrast with pattern mining
3. DO NOT forget the generation of sequence with the repetition of the same object 
	1. like pasta,pasta




## Time Contraints








