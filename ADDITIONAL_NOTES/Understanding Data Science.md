
Understand what's behind ds formulas

There is a standard for a Data Science Project called CRISP-DM.
[Pedreschi slides on the web](https://pages.di.unipi.it/pedreschi/MaterialiADEC-TDM/ADEC-slides/Slides-11-05-06_CRISP-DM.pdf)
[Guidotti](http://didawiki.di.unipi.it/lib/exe/fetch.php/magistraleinformatica/dmi/crisp-dm.pdf)


## Top-cited articles!
https://almanac.eto.tech/topics/ai/

- [Attention Is All You Need](https://doi.org/10.48550/arxiv.1706.03762)
    2017: arXiv. 83.896 citations
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://doi.org/10.18653/v1/n19-1423)
    2018: arXiv. 69.267 citations
- [PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://doi.org/10.48550/arxiv.1912.01703)
    2019: arXiv. 30.848 citations
- [Generative adversarial networks](https://doi.org/10.1145/3422622)
    2020: International Conference on Computer Vision and Pattern Analysis (ICCPA 2021). 29.526 citations
- [Squeeze-and-Excitation Networks](https://doi.org/10.1109/cvpr.2018.00745)
    2017: arXiv. 26.279 citations
- [Focal Loss for Dense Object Detection](https://doi.org/10.1109/iccv.2017.324)
    2017: arXiv. 23.910 citations
- [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://doi.org/10.1109/cvpr.2018.00474)
    2018: arXiv. 18.032 citations
- [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)
    2017: arXiv. 16.624 citations
- [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://doi.org/10.48550/arxiv.1907.11692)
    2019: arXiv. 16.492 citations
- [YOLOv3: An Incremental Improvement](https://doi.org/10.48550/arxiv.1804.02767)
    2018: arXiv. 16.319 citations